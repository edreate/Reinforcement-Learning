# [**Edreate.com â€“ Deep Reinforcement Learning Course**](https://edreate.com/courses/deep-reinforcement-learning/)

Welcome ğŸ‘‹  
This repository contains the **codebase** used in lessons from Edreateâ€™s Deep Reinforcement Learning (DRL) course.

<p align="center">
  <a href="https://edreate.com/courses/deep-reinforcement-learning/">
    <img src="https://raw.githubusercontent.com/edreate/Brand-Identity-Media/main/Logo/RGB/Logo/SVG/EdReate_Logo.svg" alt="EdReate Logo" width="200"/>
  </a>
</p>

ğŸ‘‰ For the **full learning experience**â€”including in-depth write-ups, mathematical formulas, video explanations, and structured chaptersâ€”visit the course page:
ğŸ”— [edreate.com/courses/deep-reinforcement-learning](https://edreate.com/courses/deep-reinforcement-learning/)

---

## ğŸ§­ How to explore this repo (start here!)

Begin with the **notebooks** and then check the supporting Python packages:

- [Deep Q-Learning notebook](src/deep-q-learning/01_deep_q_learning.ipynb) â€“ walk-through of DQN with code and explanations.
- [Q-Learning notebooks](src/q-learning) â€“ tabular Q-learning demos, including a 2x3 grid world.
- `src/` â€“ reusable Python packages for environments, agents, and utilities used across the lessons.
- `training_output_lunar_lander/` â€“ saved models and example training plots for the Lunar Lander Deep Q-Network run.

Keep the course site open alongside the notebooks for theory, derivations, and videos.

---

## ğŸ¤ Community

Join our [Discord server](https://discord.gg/KUstJ2jf) for learning, collaboration, and Q&A.

---

## ğŸš€ Setup Instructions

For complete setup details, see:  
[Setting Up Coding Environment and Dependencies](https://edreate.com/courses/deep-reinforcement-learning/setting-up-for-rl-course/setting-up-coding-environment-and-dependencies/)

### Quickstart (TL;DR)
Youâ€™ll need **Python** and **uv** installed.

```bash
# install uv (if not already installed)
pip install uv
```
```bash
# install all dependencies into .venv
uv sync
```

```bash
# activate the virtual environment
source .venv/bin/activate
```

```bash
# launch Jupyter
uv run jupyter notebook
```

ğŸ’¡ You can also use your favorite code editor (VS Code, PyCharm, etc.).

---

## ğŸŒŸ Algorithms Covered (Course Highlights)

<p align="center">
  <b>This repository tracks the main algorithms from the Deep RL course.</b><br/>
  Completed ones link to full lessons, others are marked <i>Coming Soon!</i>
</p>

### âœ… Available Now
- [**Deep Q-Learning**](src/deep-q-learning/01_deep_q_learning.ipynb) â€“ train value-based agents with neural networks and experience replay.
- [**Tabular Q-Learning**](src/q-learning/q_learning.ipynb) â€“ foundational algorithm for discrete environments.
- [**Grid World Q-Learning**](src/q-learning/q_learning_2x3_world.ipynb) â€“ small-world example to visualize value updates.

### ğŸ”œ Coming Soon
- **Vanilla Policy Gradient (VPG)** â€“ direct optimization of stochastic policies  
- **Actorâ€“Critic (A2C)** â€“ combining value functions with policy learning  
- **Proximal Policy Optimization (PPO)** â€“ stable, scalable policy gradients  
- **Advanced Methods** â€“ SAC and more

<p align="center">
  ğŸš§ More lessons and code will be added as the course grows!
</p>
    
---

## ğŸ“„ License

This project is licensed under the terms of the  
[LICENSE](./LICENSE) file in the root of this repository.
